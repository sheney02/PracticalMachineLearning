---
title: "Practical Machine Learning - Prediction Assignment Writeup"
author: "Nick Shenefield - Coursera"
date: "7/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#I-) Essential Packages
```{r}
IsrandomForestInstalled <- require("randomForest")
if(!IsrandomForestInstalled){
    install.packages("randomForest")
    library("randomForest")
    }

IsRpartInstalled <- require("rpart")        
if(!IsRpartInstalled){
    install.packages("rpart")
    library("rpart")
}
```

Set seed for reproducability
```{r}
set.seed(20000)
```

#II-) Data Processing
```{r}
# Load the data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"   
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
```

#III-)Cleaning data 
```{r}
# Load data to memory.
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))  
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))

# Remove variables with near zero variance
training<-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]

# Remove columns that are not predictors, which are the the seven first columns
training   <-training[,-c(1:7)]
testing <-testing[,-c(1:7)]

# The data after cleaning
dim(training)
```

#IV-) Cross-validation
```{r}
# In order to get out-of-sample errors, split the training data in training (75%) and testing (25%) data) subsets:
inTrain <- sample(nrow(training), nrow(training)*0.75)    
NEOTraining <- training[inTrain, ]
NEOTesting <- training[-inTrain, ]  
dim(NEOTraining)
dim(NEOTesting)
```

#V-) Prediction Models
```{r}
# DECISION TREE
# Fit model on NEOTraining data
fitDT <- rpart(classe ~ ., data=NEOTraining, method="class")

# Use model to predict class in validation set (NEOTesting)
predictionDT <- predict(fitDT, NEOTesting, type = "class")

#Estimate the errors of the prediction algorithm in the Decision Tree model
table(NEOTesting$classe, predictionDT, dnn = c("Actual", "Predicted"))

# RANDOM FOREST
# Fit model on NEOTraining data
fitRF <- randomForest(classe ~ ., data=NEOTraining, method="class")

# Use model to predict class in validation set (NEOTesting)
predictionRF <- predict(fitRF, NEOTesting, type = "class")

# Estimate the errors of the prediction algorithm in the Random Forest
table(NEOTesting$classe, predictionRF, dnn = c("Actual", "Predicted"))
```

#VI-) TEST THE MODEL TO PREDICT 20 DIFFERENT TEST CASES
# Perform prediction
```{r}
predictSubmission <- predict(fitRF, testing, type="class")
predictSubmission
```